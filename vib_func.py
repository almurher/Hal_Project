from re import L
from unicodedata import category
from bs4 import BeautifulSoup
import pandas as pd
from typing import final
import numpy as np
import math

'''DATA EXTRACTION'''

def report_types():
    # Type of reports generated by the inSite platform.
    
    return ['Detailed Vibration Report', 'Operating Limit Summary Report']

def report_categ_ind(soup_file):
    # Returns an index based on the file type of category.

    title_tag = str(soup_file.h1)
    category_list = report_types()
    for cat in category_list:
        if cat in title_tag:
            return category_list.index(cat)

def info_parser(soup_file, table_ind: int):
    # Returns a list (or dictionary?) with the parsed information of the well or the analysis report.
    # through the use of the BeautifulSoup.find_all() method it extracts all the tags inside the html

    table_tag = soup_file.find_all("table")[table_ind]
    row_tag = table_tag.find_all("tr")

    final_lst = []
    for tr in row_tag:
        cell_lst = []

        for td in tr:
            if td.name:
                cell_lst.append(td.string)

        final_lst.append(str(x) for x in cell_lst)

    return dict(final_lst)

def vib_val_extr(parent_div):

    final_lst = []

    # Extract values from thead tags.
    thead_list = []
    for td in parent_div.thead.tr:
        if td.name:
            thead_list.append(str(td.string))

    final_lst.append(thead_list)

    # Extract values from tbody tags.
    for tr in parent_div.tbody:
        if tr.name:
            td_list = []

            for td in tr:
                if td.name:
                    td_list.append(str(td.string))

            final_lst.append(td_list)

    return final_lst

def vol_summary_extr(soup_file, file_category_ind):
    # Returns a datastructure with the parsed values from the vibrating
    # operating limit summary. It takes as parameter the soup from each xls
    # file and the table index 3.
    # Also, it's composed of two functions...

    value_lst = []
    table_ind = file_category_ind + 2
    table_tag = soup_file.find_all("table")[table_ind]

    div_tag = table_tag.find_all("div")
    for div in div_tag:
        if div.name:
            value_lst.append([str(div.string), vib_val_extr(div.parent)])

    return value_lst

'''CREATING DATAFRAMES'''

def row_merger(df_lst):

    # Note: Not used anymore due to changes in the design of the final dataframe.
    # Help to merge rows

    new_df_lst = []
    peak_df_merged = {}

    for df in df_lst:
        string_name = str(df.loc[0, "Measure Type"]).split()
        if "Peak" in string_name:
            key_p = string_name[1]
            if key_p not in peak_df_merged:
                peak_df_merged[key_p] = [df]

            else:
                peak_df_merged[key_p].append(df)

        else:
            new_df_lst.append(df)

    if len(peak_df_merged) > 0:
            for v in peak_df_merged.values():
                if len(v) > 1:
                    v[0] = v[0].combine_first(v[1]) 

                new_df_lst.append(v[0])

    return new_df_lst

def peak_name_fix(df):
    
    # Adds the type of measure done in Peak Bins to measure type, (Mins) or (Events).
 
    bit_run_units = ['(Mins)', '(Events)', '(count)']
    for word in bit_run_units:

        if word in df.columns[2]:
            
            if word == '(count)' or word == '(Events)':
                word = '(Events)'
            filt = df['Measure Type'].str.contains('Peak', na=False)
            df.loc[filt, 'Measure Type'] = df['Measure Type'] + ' ' + word

def vib_val_df(vib_val_list):
    # Function that returns a dataframe from the list of lists from vol_summary_extr
    # merged with other data like job number, run, sensor and even tool size for average bins.

    copy_lst = vib_val_list.copy()
    # df = pd.DataFrame([extrainfo_dict])
    # df.drop(columns = "Well Name", inplace = True)
    new_list = []

    for v_lst in copy_lst:
        header = v_lst[1].pop(0)

        v_df = pd.DataFrame(v_lst[1], columns = header)
        v_df.insert(0, "Measure Type", v_lst[0])
        v_df.iloc[:, 2] = [float(x) for x in v_df.iloc[:, 2]]
        peak_name_fix(v_df)
        new_list.append(v_df)

    return new_list

def info_merger_df(well_dict, vols_dict):
    # It takes both well information and the vibration operating limits summary
    # information data structures and returns a merged dataframe.

    well_copy = well_dict.copy()
    well_copy.update(vols_dict)
    
    # If needed here the dataframe can be cleaned for a future update...
    df = pd.DataFrame([well_copy])
    return df

def final_merger_df(well_dict, vols_dict, vib_val_dict_df):
    # Returns the raw final dataframe for this file.
    fin_df = pd.DataFrame()
    well_copy = well_dict.copy()
    well_copy.update(vols_dict)
    key_list = list(well_copy.keys())
    value_list = list(well_copy.values())

    for df in vib_val_dict_df:
        temp_df = df.copy()
        for i in range(len(key_list) - 1, -1, -1):
            temp_df.insert(0, key_list[i], value_list[i])

        fin_df = pd.concat([fin_df, temp_df]).reset_index(drop = True)
    
    return fin_df


'''DATA CLEANING'''

def df_modifier(df, file_category, file_name):
    
    # This function integers different functions related to modify the final
    # dataframe. it's only purpose is give more order to the script.
    tool_name = na_vib_tool_finder(df, file_name)
    del_av_bin_neg(df, file_category)
    column_eraser(df, file_category)
    column_replacer(df, 'M/LWD Tool Size', '6 Â¾" and smaller', '6 ¾" and smaller')
    column_replacer(df, 'Vibration Tool', 'N/A', tool_name)
    df.replace('None', np.nan, inplace=True)
    
def column_eraser(df, file_category):
    # Deletes columns that are considered useless for either reports.
    col_stnd = ['Rig Name','Activity Code', 'Report Generation Date and Time']
    col_stnd.extend(col_to_del(file_category))
    df.drop(columns=col_stnd, inplace=True)

def col_to_del(file_category):

    valid = report_types()
    if file_category not in valid:
        raise ValueError(f'Resultados: status debe ser una opción de {valid.join()}')
    
    if file_category == valid[0]:
        # Columns considered not useful for a Detailed Vibration Report.
        return ['Depth Range selected', 'Date/Time Range selected']

        # Columns considered not useful for a Operating Limit Summary Report.
    return ['GP RPM Filter Min Value', 'GP RPM Filter Max Value']
    
def del_av_bin_neg(df, file_category):

    # Reports contain two tables with "Delta Average Bins" however one of them has
    # negative Bands (G) so this function add a "(-)" to differenciate between each
    # table.
    valid = report_types()
    if file_category == valid[1]:
        filt = df['Band (G)'].str.contains('-', na=False)
        df.loc[filt, 'Measure Type'] = 'Delta Average Bins (-)'

def column_replacer(df, colmn, old_content, new_content):

    filter = (df[colmn] == old_content)
    df.loc[filter, colmn] = new_content

def na_vib_tool_finder(df, file_name):
    # Finds and returns the tool name from the file name in case it isn't available in the report.
    end_index = file_name.find('-')
    string_lst = file_name[:end_index].split()
    start_index = 0
    for i in range(len(string_lst)):
        if string_lst[i] == 'VLA':
            start_index = i

    return '-'.join(string_lst[start_index + 1:])

'''ACCUMULATIVE FILTERS'''

def df_adapter(basic_df):

    # The function merges the different Bands and Bit Run columns into a single one for each case.
    df = basic_df.copy()
    df['Band'] = df['Band (G)'].combine_first(df['Band (%)'])
    df['Bit Run'] = df['Bit Run (Mins)'].combine_first(df['Bit Run (count)'])
    df.drop(['Band (G)', 'Band (%)', 'Bit Run (Mins)', 'Bit Run (count)'], axis=1, inplace=True)

    if 'Op Limit (Events)' in df.columns and 'Op Limit (Mins)' in df.columns:
        df['Op Limit'] = df['Op Limit (Mins)'].combine_first(df['Op Limit (Events)'])
        df.drop(['Op Limit (Mins)', 'Op Limit (Events)'], axis=1, inplace=True)
        df['Op Limit'] = df['Op Limit'].astype('float32')

    elif 'Op Limit (Mins)' in df.columns:
        df['Op Limit'] = df['Op Limit (Mins)']
        df.drop(['Op Limit (Mins)'], axis=1, inplace=True)
        df['Op Limit'] = df['Op Limit'].astype('float32')

    return df

def sum_data_filter(df):
    # Filters columns for a specific set of values and returns a new column with sums.
    
    if 'Op Limit' in df.columns:
        new_df = df.groupby(['Job Number', 'Vibration Tool', 'M/LWD Tool Size', 'Measure Type', 'Band']).agg(Bit_Run_Tot = ('Bit Run', 'sum'), Op_Lim = ('Op Limit', 'max')).round(2)  
        return new_df
    
    new_df = df.groupby(['Job Number', 'Vibration Tool', 'M/LWD Tool Size', 'Measure Type', 'Band'])['Bit Run'].apply(sum).rename('Bit_Run_Tot').round(2)
    return new_df

def surpass_op_lim(df):
    # Checks out if the accumulative Bit Run is higher than the operating limits values and returns a list of lists.
    df = df.reset_index()

    if 'Op_Lim' in df.columns:
        filt = (df['Bit_Run_Tot'] > df['Op_Lim'])
        df_list = df[filt].values.tolist()

        return df_list

def available_tools(df):
    # Returns a list of vibration tools found in the dataframe.
    return list(df['Vibration Tool'].unique())

'''DATA EXPORTING'''

def export_xls(df, file_name, output_path):
    # Exports dataframes to excel.
    df_name = f'{file_name}.xlsx'
    with pd.ExcelWriter(f'{output_path}/output/{df_name}') as writer:
        df.to_excel(writer, index=False, header=True)

